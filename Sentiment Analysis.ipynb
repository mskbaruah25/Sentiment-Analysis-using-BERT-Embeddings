{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8cea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 10)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  ProductId  UserId  ProfileName  HelpfulnessNumerator  \\\n",
       "0       False      False   False        False                 False   \n",
       "1       False      False   False        False                 False   \n",
       "2       False      False   False        False                 False   \n",
       "3       False      False   False        False                 False   \n",
       "4       False      False   False        False                 False   \n",
       "...       ...        ...     ...          ...                   ...   \n",
       "568449  False      False   False        False                 False   \n",
       "568450  False      False   False        False                 False   \n",
       "568451  False      False   False        False                 False   \n",
       "568452  False      False   False        False                 False   \n",
       "568453  False      False   False        False                 False   \n",
       "\n",
       "        HelpfulnessDenominator  Score   Time  Summary   Text  \n",
       "0                        False  False  False    False  False  \n",
       "1                        False  False  False    False  False  \n",
       "2                        False  False  False    False  False  \n",
       "3                        False  False  False    False  False  \n",
       "4                        False  False  False    False  False  \n",
       "...                        ...    ...    ...      ...    ...  \n",
       "568449                   False  False  False    False  False  \n",
       "568450                   False  False  False    False  False  \n",
       "568451                   False  False  False    False  False  \n",
       "568452                   False  False  False    False  False  \n",
       "568453                   False  False  False    False  False  \n",
       "\n",
       "[568454 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordlen(x):\n",
    "    return len(x.split())\n",
    "data['len'] = data.Text.apply(get_wordlen)\n",
    "data = data[data.len<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(n=100000, random_state = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mod(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    elif x >3 :\n",
    "        return 1\n",
    "    elif x == 3:\n",
    "        return 2\n",
    "\n",
    "data['Score'] = data['Score'].map(mod)\n",
    "data['Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    filtered_text = []\n",
    "    for i in text.split():\n",
    "        i = i.lower()\n",
    "        if i not in stop_words:\n",
    "            filtered_text.append(i)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = re.sub(\"\\S*\\d\\S*\", \"\", text).strip()\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    text = re.sub('<.*?>','',text)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I fill this toy with cereal to keep my high maintenance Lab occupied for hours He is become very proficient at extracting pieces from the toy but it still is a challenge for him Fabulous indestructible toy Great investment for my money ',\n",
       " 'Ahh the taste of cherries in the spring and the smell too When this arrived today I was eager to brew my first cup The contemplation this prompts in me is such a joy ',\n",
       " 'If you like your Keurig you need to try this K cup Smooth taste with just a slight hint of flavor Not overwhelming like some brands My new favorite ',\n",
       " 'The oz is the best way to get these and to save money They taste great I have already eaten half of thw Tub already',\n",
       " 'We actually went to Big Bob is restaurant in Alabama and got hooked on his sauces We love the habanero red sauce because it has a little bit of a kick but not too much Try one and you will order a case just as we did ',\n",
       " 'I do not have food allergies but am going to buy this mix A friend made it and it is ABSOLUTELY delicious She said they delete the egg and water and do snack size applesauces SOOO good ',\n",
       " 'Nice new blend I am starting to like this one A change of pace not bitter or too strong but still has a lot of flavor Try a box or two and see I have it on the subscription program with Amazon and it works well ',\n",
       " 'I ordered these for my upcoming wedding candy buffet I am doing all navy and white and these go perfectly They are individually wrapped and a true navy color The packaging was great Each lollipop is wrapped in bubble wrap Love them ',\n",
       " 'these honey roasted pecans are absolutaly the best when i started eating i could not eat just one i will buy more ',\n",
       " 'My baby loves most of the Earths Best foods I really like that this is a variety pack and wish the company would make more variety packs of all their foods Cost is much cheaper with free shipping than I can find these foods locally ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data['Text'].values\n",
    "preprocessed_text =[]\n",
    "for i in text:\n",
    "    preprocessed = preprocess_text(i)\n",
    "    preprocessed_text.append(preprocessed)\n",
    "    \n",
    "preprocessed_text[:10]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(len(data['Score'].values))\n",
    "print(len(preprocessed_text))\n",
    "print(len(data['Text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"Score\"].values\n",
    "X = preprocessed_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,x_test,y_train,y_test = train_test_split(X,y, test_size = 0.20, stratify = y, random_state = 33)\n",
    "y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "max_seq_length = 50\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a97f3b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.bool_'>\n"
     ]
    }
   ],
   "source": [
    "print(type(do_lower_case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenization\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(X):\n",
    "    max_seq_len = 50\n",
    "    token_train = tokenizer.tokenize(X)\n",
    "    token_train = token_train[0: (max_seq_len-2)]\n",
    "    token_train = ['[CLS]', *token_train, '[SEP]']\n",
    "    len_before = len(token_train)\n",
    "    if (len(token_train) < max_seq_len):\n",
    "        for i in range (len(token_train), 50):\n",
    "            token_train.append('[PAD]')\n",
    "    token_train = tokenizer.convert_tokens_to_ids(token_train)\n",
    "    mask_train = ([1]*len_before + [0]* (max_seq_len - len_before))\n",
    "    segment_train = [0]*max_seq_length\n",
    "    \n",
    "    return token_train, mask_train, segment_train\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokens = []\n",
    "X_test_tokens = []\n",
    "X_train_mask = []\n",
    "X_test_mask = []\n",
    "X_train_segment = []\n",
    "X_test_segment = []\n",
    "\n",
    "for i in X_train:\n",
    "    token_train, mask_train, segment_train = tokenization(i)\n",
    "    X_train_tokens.append(token_train)\n",
    "    X_train_mask.append(mask_train)\n",
    "    X_train_segment.append(segment_train)\n",
    "    \n",
    "for i in x_test:\n",
    "    token_test, mask_test, segment_test = tokenization(i)\n",
    "    X_test_tokens.append(token_test)\n",
    "    X_test_mask.append(mask_test)\n",
    "    X_test_segment.append(segment_test)\n",
    "\n",
    "    \n",
    "X_train_tokens = np.array(X_train_tokens)    \n",
    "X_test_tokens = np.array(X_test_tokens)\n",
    "X_train_mask = np.array(X_train_mask)\n",
    "X_test_mask = np.array(X_test_mask)\n",
    "X_train_segment = np.array(X_train_segment)\n",
    "X_test_segment = np.array(X_test_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 50)\n",
      "(80000, 50)\n",
      "(80000, 50)\n",
      "(20000, 50)\n",
      "(20000, 50)\n",
      "(20000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tokens.shape)\n",
    "print(X_train_mask.shape)\n",
    "print(X_train_segment.shape)\n",
    "print(X_test_tokens.shape)\n",
    "print(X_test_mask.shape)\n",
    "print(X_test_segment.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open('train_data.pkl','wb'))\n",
    "pickle.dump((x_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open('test_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pooled_output=bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pooled_output = bert_model.predict([X_test_tokens, X_test_mask, X_test_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e3f2816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp_exp = X_train_pooled_output[0].reshape(1,-1)\n",
    "X_temp_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, Flatten, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 768)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               393728    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 558,339\n",
      "Trainable params: 558,339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "Input_layer = Input(shape = X_train_pooled_output.shape[1])\n",
    "Layer1 = Dense(512, activation = 'relu', kernel_initializer = 'he_normal')(Input_layer)\n",
    "Layer2 = Dense(256, activation = 'relu', kernel_initializer = 'he_normal')(Layer1)\n",
    "Layer3 = Dense(128, activation = 'relu', kernel_initializer = 'he_normal')(Layer2)\n",
    "Layer4 = Dense(64, activation ='relu', kernel_initializer = 'he_normal')(Layer2)\n",
    "Output = Dense(3, activation = 'softmax', kernel_initializer = 'he_normal')(Layer3)\n",
    "\n",
    "model_nn = Model(inputs = Input_layer, outputs = Output)\n",
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 3)\n",
      "(20000, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "y_train_new = encoder.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test_new = encoder.transform(y_test.reshape(-1,1)).toarray()\n",
    "print(y_train_new.shape)\n",
    "print(y_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.2612 - auc: 0.9449 - accuracy: 0.8445 - val_loss: 0.3326 - val_auc: 0.9203 - val_accuracy: 0.7561\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 67s 8ms/step - loss: 0.2360 - auc: 0.9540 - accuracy: 0.8575 - val_loss: 0.2531 - val_auc: 0.9434 - val_accuracy: 0.8482\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.2295 - auc: 0.9558 - accuracy: 0.8619 - val_loss: 0.2166 - val_auc: 0.9620 - val_accuracy: 0.8684\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 67s 8ms/step - loss: 0.2247 - auc: 0.9578 - accuracy: 0.8624 - val_loss: 0.2240 - val_auc: 0.9596 - val_accuracy: 0.8603\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.2226 - auc: 0.9584 - accuracy: 0.8650 - val_loss: 0.2125 - val_auc: 0.9634 - val_accuracy: 0.8704\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.2201 - auc: 0.9593 - accuracy: 0.8663 - val_loss: 0.2203 - val_auc: 0.9581 - val_accuracy: 0.8639\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.2181 - auc: 0.9601 - accuracy: 0.8669 - val_loss: 0.2256 - val_auc: 0.9657 - val_accuracy: 0.8721\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 67s 8ms/step - loss: 0.2173 - auc: 0.9602 - accuracy: 0.8678 - val_loss: 0.2135 - val_auc: 0.9658 - val_accuracy: 0.8719\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.2151 - auc: 0.9610 - accuracy: 0.8683 - val_loss: 0.2103 - val_auc: 0.9635 - val_accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.2137 - auc: 0.9612 - accuracy: 0.8694 - val_loss: 0.2208 - val_auc: 0.9571 - val_accuracy: 0.8676\n"
     ]
    }
   ],
   "source": [
    "optimizer_nn = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "tb_model_nn = tf.keras.callbacks.TensorBoard(log_dir = \"logs_model_nn/\", histogram_freq = 1)\n",
    "model_nn.compile(optimizer = optimizer_nn, loss =tf.keras.losses.BinaryCrossentropy(), metrics =[tf.keras.metrics.AUC(from_logits = True), 'accuracy'])\n",
    "history_nn = model_nn.fit(X_train_pooled_output, y_train_new, batch_size = 10, epochs = 10, validation_data = (X_test_pooled_output, y_test_new), callbacks =[tb_model_nn])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cfb23039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_nn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_nn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 326). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_bert\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_bert\\assets\n"
     ]
    }
   ],
   "source": [
    "model_nn.save(\"model_nn\")\n",
    "bert_model.save(\"model_bert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9557f5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_nn_test = load_model(\"model_nn\")\n",
    "bert_model_test = load_model(\"model_bert\")\n",
    "bert_layer_test = hub.KerasLayer(hub.load(\"bert_layer_downloaded\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36578691",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenization\n",
    "vocab_file_temp = bert_layer_test.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case_temp = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer_temp = tokenization.FullTokenizer(vocab_file_temp, do_lower_case_temp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1eee9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization_temp(X):\n",
    "    max_seq_len = 50\n",
    "    token_train = tokenizer_temp.tokenize(X)\n",
    "    token_train = token_train[0: (max_seq_len-2)]\n",
    "    token_train = ['[CLS]', *token_train, '[SEP]']\n",
    "    len_before = len(token_train)\n",
    "    if (len(token_train) < max_seq_len):\n",
    "        for i in range (len(token_train), 50):\n",
    "            token_train.append('[PAD]')\n",
    "    token_train = tokenizer_temp.convert_tokens_to_ids(token_train)\n",
    "    mask_train = ([1]*len_before + [0]* (max_seq_len - len_before))\n",
    "    segment_train = [0]*max_seq_length\n",
    "    \n",
    "    return token_train, mask_train, segment_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bd5b331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01513118, 0.9350167 , 0.04985212]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test = model_nn_test.predict(X_temp_exp)\n",
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ecbec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3279397e-05 9.9993253e-01 4.4232227e-05]]\n"
     ]
    }
   ],
   "source": [
    "X_temp = 'I found this product to be extremely useful  to me. I would recommend anyone who is struggling with weight loss to use this product'\n",
    "X_temp = preprocess_text(X_temp)\n",
    "X_temp_tokens = []\n",
    "X_temp_mask = []\n",
    "X_temp_segment =[]\n",
    "temp_tokens, temp_mask, temp_segment = tokenization_temp(X_temp)\n",
    "X_temp_tokens.append(temp_tokens)\n",
    "X_temp_mask.append(temp_mask)\n",
    "X_temp_segment.append(temp_segment)\n",
    "X_temp_tokens =np.array(X_temp_tokens)\n",
    "X_temp_mask = np.array(X_temp_mask)\n",
    "X_temp_segment = np.array(X_temp_mask)\n",
    "X_temp_pooled_output = bert_model_test.predict([X_temp_tokens, X_temp_mask, X_temp_segment])\n",
    "print(model_nn_test.predict(X_temp_pooled_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83f2c1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbe004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42e545c60a4a06c05f8c1e976e9274b7d3dee4a984c8399fe25bfeff5933ef28"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
